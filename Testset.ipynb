{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        # (((178−2)/2)−2)/2=43\n",
    "        # (((218−2)/2)−2)/2=53\n",
    "        self.fc1 = nn.Linear(43*53*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 43*53*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "# A1model = torch.load('./A1/A1RegnetY16GFModel.pt')\n",
    "A2model = ConvolutionalNetwork()\n",
    "A2model.load_state_dict(torch.load('./A2/A2CNNModelFinal.pt'))\n",
    "# A2model = torch.load('./A2/A2CNNModelFinal.pt')\n",
    "# B1model = torch.load('./B2/B2CNNModelFinal.pt')\n",
    "# B2model = torch.load('./B1/B2CNNModelFinal.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "        # Requirements for pretrained models:\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, task, part, root_dir, label_file, class_names, class_to_idx, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_file = label_file\n",
    "        self.class_names = class_names\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read the labels from the Excel file\n",
    "        if (task == 'A' and part == 1): \n",
    "            self.labels = pd.read_csv('./Datasets/celeba_test/labels.csv', usecols=[2], delimiter='\\t')['gender'].tolist()\n",
    "        if (task == 'A' and part == 2):\n",
    "            self.labels = pd.read_csv('./Datasets/celeba_test/labels.csv', usecols=[3], delimiter='\\t')['smiling'].tolist()\n",
    "        if (task == 'B' and part == 1): \n",
    "            self.labels = pd.read_csv('./Datasets/cartoon_set_test/labels.csv', usecols=[2])['face_shape'].tolist()\n",
    "        if (task == 'B' and part == 2):\n",
    "            self.labels = pd.read_csv('./Datasets/cartoon_set_test/labels.csv', usecols=[1])['eye_color'].tolist()\n",
    "        \n",
    "        # Get the list of image files (without the lambda it was not in order)\n",
    "        self.image_files = []\n",
    "        for root, dirs, files in os.walk(root_dir): \n",
    "            self.image_files.extend([os.path.join(root, file) for file in sorted(files, key=lambda x: int(''.join(filter(str.isdigit, x))))])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image and apply the transformation\n",
    "        image = Image.open(self.image_files[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert the label to a tensor\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define the root directory of the dataset and the label file\n",
    "root_dir_test = './Datasets/celeba_test/img'\n",
    "label_file_test = './Datasets/cartoon_set_test/img'\n",
    "# Define the class names and their corresponding indexes\n",
    "class_names = ['men', 'women']\n",
    "class_to_idx = {'men': 1, 'women': -1}\n",
    "\n",
    "A1test_data = MyDataset('A', 1, root_dir_test, label_file_test, class_names, class_to_idx, transform=test_transform)\n",
    "A2test_data = MyDataset('A', 2, root_dir_test, label_file_test, class_names, class_to_idx, transform=test_transform)\n",
    "B1test_data = MyDataset('B', 1, root_dir_test, label_file_test, class_names, class_to_idx, transform=test_transform)\n",
    "B2test_data = MyDataset('B', 2, root_dir_test, label_file_test, class_names, class_to_idx, transform=test_transform)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "A1test_loader = DataLoader(A1test_data, batch_size=125, shuffle=True)\n",
    "A2test_loader = DataLoader(A2test_data, batch_size=125, shuffle=True)\n",
    "B1test_loader = DataLoader(B1test_data, batch_size=125, shuffle=True)\n",
    "B2test_loader = DataLoader(B2test_data, batch_size=125, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyDataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Run the testing batches\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m b, (X_test, y_test) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(A2test_loader):\n\u001b[0;32m      8\u001b[0m         \u001b[39m# Changing the labels to be in the range [0, num_classes-1].\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         y_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(y_test \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, torch\u001b[39m.\u001b[39mtensor(\u001b[39m1\u001b[39m), torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m))\n\u001b[0;32m     11\u001b[0m         \u001b[39m# Apply the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     35\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Convert the label to a tensor\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels[idx])\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m image, label\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MyDataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "test_correct = []\n",
    "predictions = []\n",
    "\n",
    "# Run the testing batches\n",
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(A2test_loader):\n",
    "        # Changing the labels to be in the range [0, num_classes-1].\n",
    "        y_test = torch.where(y_test == 1, torch.tensor(1), torch.tensor(0))\n",
    "\n",
    "        # Apply the model\n",
    "        y_val = A2model(X_test)\n",
    "\n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_val.data, 1)[1]\n",
    "        predictions.append(predicted)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed1ccafe2886438cd66fc9b7e8bf40908e255cd6b5e541ecda7c81a69f38205e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
